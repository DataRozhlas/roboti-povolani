{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the job grouplists\n",
    "rooturl = \"https://www.nsp.cz/odborny-smer\"\n",
    "rootpage = requests.get(rooturl).text\n",
    "rootsoup = BeautifulSoup(rootpage, 'html.parser')\n",
    "sel = rootsoup.select(\".bricklayer li a\")\n",
    "rootlinks = [a[\"href\"] for a in sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in rootlinks:\n",
    "    if link == \"https://www.nsp.cz/odborny-podsmer-rozsireny/ozbrojene-sily-a-bezpecnostni-sbory\":\n",
    "        link = \"https://www.nsp.cz/odborny-smer/ozbrojene-sily-a-bezpecnostni-sbory\"\n",
    "    print(link)\n",
    "    group_json = requests.get(link + \"?view=0&_format=json\", headers={\"x-requested-with\": \"XMLHttpRequest\"}).json()\n",
    "    for entry in group_json['data']:\n",
    "        for subentry in entry['items']['s1']:\n",
    "            if subentry['children']:\n",
    "                for child in subentry['children']:\n",
    "                    jobdict[child['title']] = {'url': child['urlSlug']}\n",
    "            else:\n",
    "                jobdict[subentry['title']] = {'url': subentry['urlSlug']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the individual pages\n",
    "print(len(jobdict))\n",
    "i = 0\n",
    "for job in jobdict:\n",
    "    i += 1\n",
    "    print(i, end=\" \")\n",
    "    subsrc = requests.get(\"https://www.nsp.cz/jednotka-prace/\" + jobdict[job]['url']).text\n",
    "    subsrcsoup = BeautifulSoup(subsrc, 'html.parser')\n",
    "    jobsrc = subsrcsoup.select(\".search-results__results > li\")\n",
    "    jobdict[job][\"skills\"] = {}\n",
    "    skills = {\"odb_dov\": \"#TYPE_TECHNICAL_HARD_SKILL\", \"odb_zna\": \"#TYPE_SPECIFIC_HARD_SKILL\", \"obecne\": \"#TYPE_GENERIC_HARD_SKILL\", \"mekke\": \"#TYPE_SOFT_SKILL\"}\n",
    "    for skill in skills:\n",
    "        subskills = {}\n",
    "        skillsoup = subsrcsoup.select(skills[skill]+\" tbody tr\")\n",
    "\n",
    "        for subskill in skillsoup:\n",
    "            subskills[subskill.get_text().strip()] = len(subskill.select(\".circle--green\"))\n",
    "        jobdict[job][\"skills\"][skill] = subskills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobdict:\n",
    "    if len(jobdict[job][\"skills\"]) == 0:\n",
    "        print(jobdict[job])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/jobs.json\",\"w\",encoding=\"utf-8\") as file:\n",
    "    file.write(json.dumps(jobdict, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
